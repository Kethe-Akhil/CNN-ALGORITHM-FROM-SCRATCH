{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac671ae3-c491-477f-8fef-2284c3e8f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5740f5c0-67eb-4e7f-a7d7-bca094f1eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network:\n",
    "    def __init__(self,learning_rate,epochs,output_size,hidden_layer_size,k1,k2,x):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epochs=epochs\n",
    "        self.output_size=output_size\n",
    "        self.hidden_layer_size=hidden_layer_size\n",
    "        self.k1=k1\n",
    "        self.k2=k2\n",
    "        self.x=x\n",
    "        kh,kw=3,3\n",
    "        N,heightinp1,widthinp1,channelsinp1=self.x.shape\n",
    "        self.kernel1=np.random.randn(kh,kw,channelsinp1,self.k1)*0.01\n",
    "        self.bias1=np.zeros(self.k1)\n",
    "        self.kernel2=np.random.randn(kh,kw,self.k1,self.k2)*0.01\n",
    "        self.bias2=np.zeros(self.k2)\n",
    "        s=1\n",
    "        conv2_hout=((heightinp1-2*kh)//s)+2\n",
    "        conv2_wout=((widthinp1-2*kw)//s)+2\n",
    "        flattened=(N,conv2_hout*conv2_wout*self.k2)\n",
    "        self.w1=np.random.randn(flattened[1],self.hidden_layer_size)*0.01\n",
    "        self.b1=np.zeros((1,self.hidden_layer_size))\n",
    "        self.w2=np.random.randn(self.hidden_layer_size,self.output_size)*0.01\n",
    "        self.b2=np.zeros((1,self.output_size))\n",
    "        self.accuracy_history=[]\n",
    "        self.loss_history=[]\n",
    "    def relu(self,z):\n",
    "        return np.maximum(z,0)\n",
    "    def reluderivative(self,z):\n",
    "        return np.where(z>0,1,0)\n",
    "    def softmax(self,z):\n",
    "        z=z-np.max(z, axis=1,keepdims=True)\n",
    "        expz=np.exp(z)\n",
    "        return expz/np.sum(expz,axis=1,keepdims=True)\n",
    "    def accuracy(self,y,y_pred):\n",
    "        y_pre=np.argmax(y_pred,axis=1)\n",
    "        y_true=np.argmax(y,axis=1)\n",
    "        return np.mean(y_pre==y_true)\n",
    "    def loss(self, y_pred, y):\n",
    "        eps = 1e-9\n",
    "        y_pred = np.clip(y_pred,eps,1-eps)\n",
    "        return -np.mean(np.sum(y*np.log(y_pred),axis=1))\n",
    "\n",
    "    def forward_conv(self,s):\n",
    "        N,heightinp1,widthinp1,channelsinp1=self.x.shape\n",
    "        k1h,k1w,k1c,k1n=self.kernel1.shape\n",
    "        k2h,k2w,k2c,k2n=self.kernel2.shape\n",
    "        h_out1=((heightinp1-k1h)//s)+1\n",
    "        w_out1=((widthinp1-k1w)//s)+1\n",
    "        x_input1=np.zeros((N,h_out1*w_out1,k1h*k1w*k1c))\n",
    "        self.conv1op1=np.zeros((N,h_out1*w_out1,k1n))\n",
    "        for n in range(N):\n",
    "            index=0\n",
    "            for i in range(0,h_out1,s):\n",
    "                for j in range(0,w_out1,s):\n",
    "                    patch=self.x[n,i:i+k1h,j:j+k1w,:]\n",
    "                    x_input1[n,index,:]=patch.flatten()\n",
    "                    index+=1\n",
    "            self.conv1op1[n]=np.dot(x_input1[n],self.kernel1.reshape(-1,k1n))+self.bias1.reshape(-1,k1n)\n",
    "        self.conv1op1=self.conv1op1.reshape(N,h_out1,w_out1,k1n)\n",
    "        self.relu_output1=self.relu(self.conv1op1)\n",
    "        _,heightinp1,widthinp1,channeslinp1=self.relu_output1.shape\n",
    "        h_out1=((heightinp1-k2h)//s)+1\n",
    "        w_out1=((widthinp1-k2w)//s)+1\n",
    "        \n",
    "        x_input2=np.zeros((N,h_out1*w_out1,k2h*k2w*k1n))\n",
    "        self.conv2op1=np.zeros((N,h_out1*w_out1,k2n))\n",
    "        for n in range(N):\n",
    "            index=0\n",
    "            for i in range(0,h_out1,s):\n",
    "                for j in range(0,w_out1,s):\n",
    "                    patch=self.relu_output1[n,i:i+k2h,j:j+k2w,:]\n",
    "                    x_input2[n,index,:]=patch.flatten()\n",
    "                    index+=1\n",
    "            self.conv2op1[n]=np.dot(x_input2[n],self.kernel2.reshape(-1,k2n))+self.bias2.reshape(-1,k2n)\n",
    "        self.conv2op1=self.conv2op1.reshape(N,h_out1,w_out1,k2n)\n",
    "        self.relu_output2=self.relu(self.conv2op1)\n",
    "        flatted=self.relu_output2.reshape(N,-1)\n",
    "        self.z1=np.dot(flatted,self.w1)+self.b1\n",
    "        self.r1=self.relu(self.z1)\n",
    "        self.z2=np.dot(self.r1,self.w2)+self.b2\n",
    "        y_pred=self.softmax(self.z2)\n",
    "        return y_pred,flatted\n",
    "    def backpropagation(self,y,y_pred,flatted,s=1):\n",
    "        k1h,k1w,k1c,k1n=self.kernel1.shape\n",
    "        k2h,k2w,k2c,k2n=self.kernel2.shape\n",
    "        N,h_out1,w_out1,chanels=self.relu_output2.shape\n",
    "        _,h_out2,w_out2,_=self.relu_output1.shape\n",
    "        \n",
    "        error=y_pred-y\n",
    "        \n",
    "        gradientsw2=np.dot(self.r1.T,error)/len(y)\n",
    "        gradientsb2=np.sum(error,axis=0)/len(y)\n",
    "\n",
    "        errorz1=np.dot(error,self.w2.T)*self.reluderivative(self.z1)\n",
    "        \n",
    "        gradientsw1=np.dot(flatted.T,errorz1)/len(y)\n",
    "        gradientsb1=np.sum(errorz1,axis=0)/len(y)\n",
    "\n",
    "        gradientsreluop1=np.dot(errorz1,self.w1.T)\n",
    "        gradientsreluop1=gradientsreluop1.reshape(N,h_out1,w_out1,k2n)\n",
    "        convdelta2=gradientsreluop1*self.reluderivative(self.conv2op1)\n",
    "        convdelta2=convdelta2.reshape(N,h_out1*w_out1,k2n)\n",
    "        relu1reshape=np.zeros((N,h_out1*w_out1,k2h*k2w*k2c))\n",
    "        for n in range(N):\n",
    "            index=0\n",
    "            for i in range(0,h_out1,s):\n",
    "                for j in range(0,w_out1,s):\n",
    "                    patch=self.relu_output1[n,i:i+k2h,j:j+k2w,:]\n",
    "                    relu1reshape[n,index,:]=patch.flatten()\n",
    "                    index+=1\n",
    "        gradientsk2=np.einsum('npi,npo->io',relu1reshape,convdelta2)\n",
    "        gradientsk2=gradientsk2.reshape(k2h,k2w,k2c,k2n)\n",
    "        gradientsb22=np.sum(convdelta2,axis=(0,1))\n",
    "\n",
    "        pad=k1h-1\n",
    "        convdelta2=convdelta2.reshape(N,h_out1,w_out1,k2n)\n",
    "\n",
    "        error_pad=np.pad(convdelta2,pad_width=((0,0,),(pad,pad),(pad,pad),(0,0)),mode='constant')\n",
    "        flipped_kernel=self.kernel2[::-1,::-1,:,:]\n",
    "        flipped_kernel=np.transpose(flipped_kernel,(0,1,3,2))\n",
    "        flipped_kernel=flipped_kernel.reshape(-1,k2c)\n",
    "        \n",
    "        \n",
    "        temprelu=np.zeros((N,h_out2*w_out2,k2h*k2w*k2n))\n",
    "        conv11op1=np.zeros((N,h_out2*w_out2,k2c))\n",
    "        \n",
    "        for n in range(N):\n",
    "            index=0\n",
    "            for i in range(0,h_out2,s):\n",
    "                for j in range(0,w_out2,s):\n",
    "                    patch=error_pad[n,i:i+k2h,j:j+k2w,:]\n",
    "                    temprelu[n,index,:]=patch.flatten()\n",
    "                    index+=1\n",
    "            conv11op1[n]=np.dot(temprelu[n],flipped_kernel)\n",
    "        conv11op1=conv11op1.reshape(N,h_out2,w_out2,k2c)\n",
    "        conv11op1=conv11op1*self.reluderivative(self.conv1op1)\n",
    "\n",
    "        x_col=np.zeros((N,h_out2*w_out2,k1h*k1w*k1c))\n",
    "        \n",
    "        for n in range(N):\n",
    "            index=0\n",
    "            for i in range(0,h_out2,s):\n",
    "                for j in range(0,w_out2,s):\n",
    "                    patch=self.x[n,i:i+k1h,j:j+k1w,:]\n",
    "                    x_col[n,index,:]=patch.flatten()\n",
    "            conv11op1=conv11op1.reshape(N,h_out2*w_out2,k2c)   \n",
    "        gradientsk1=np.einsum('npi,npo->io',x_col,conv11op1)\n",
    "        gradientsk1=gradientsk1.reshape(k1h,k1w,k1c,k1n)\n",
    "        gradientsb11=np.sum(conv11op1,axis=(0,1))\n",
    "\n",
    "\n",
    "        self.w2-=self.learning_rate*gradientsw2\n",
    "        self.b2-=self.learning_rate*gradientsb2\n",
    "        self.w1-=self.learning_rate*gradientsw1\n",
    "        self.b1-=self.learning_rate*gradientsb1\n",
    "        self.kernel2-=self.learning_rate*gradientsk2\n",
    "        self.bias2-=self.learning_rate*gradientsb22\n",
    "        self.kernel1-=self.learning_rate*gradientsk1\n",
    "        self.bias1-=self.learning_rate*gradientsb11\n",
    "    def training(self,x,y):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred,flatted=self.forward_conv(s=1)\n",
    "            acc=self.accuracy(y_pred,y)\n",
    "            self.accuracy_history.append(acc)\n",
    "            los=self.loss(y_pred,y)\n",
    "            self.loss_history.append(los)\n",
    "            self.backpropagation(y,y_pred,flatted,1)\n",
    "            if epoch%10==0:\n",
    "                print(f'epoch number:{epoch} and accuracy:{self.accuracy_history[epoch]} loss:{self.loss_history[epoch]}')\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ebe40-332f-444c-8c8c-359151ada92a",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763aef6-d9b8-4555-88f3-68ec0235994c",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "en=OneHotEncoder(sparse_output=True)\n",
    "y_train=y_train.reshape(-1,1)\n",
    "y=en.fit_transform(y_train).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65af23-1a1e-48d9-abd5-69fb80a215a5",
   "metadata": {},
   "source": [
    "y=y[:100]\n",
    "x=x_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1102d3c1-dcf8-4f13-a703-9be6292ed840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a355479f-5a7f-459e-884e-98ce07be7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1ae2e1b8-7f15-4b8e-8763-bcaa3a51a2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 28, 28, 1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4b8b38c2-375a-4880-9179-bf6c75eabef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=neural_network(0.001,100,10,10,3,4,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2c908668-c19b-4514-b392-2cb61fa4d76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number:0 and accuracy0.07 loss2.3024980315355617\n",
      "epoch number:10 and accuracy0.13 loss2.3023790749156903\n",
      "epoch number:20 and accuracy0.17 loss2.3022614870406417\n",
      "epoch number:30 and accuracy0.15 loss2.302143379814563\n",
      "epoch number:40 and accuracy0.15 loss2.302021105470434\n",
      "epoch number:50 and accuracy0.15 loss2.3018971159436346\n",
      "epoch number:60 and accuracy0.16 loss2.3017706607492197\n",
      "epoch number:70 and accuracy0.16 loss2.3016411908612535\n",
      "epoch number:80 and accuracy0.16 loss2.3015068601393565\n",
      "epoch number:90 and accuracy0.16 loss2.3013640802386277\n"
     ]
    }
   ],
   "source": [
    "cnn.training(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1078bfd5-6465-444b-905a-19b8e81fbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k=np.random.randn(3,3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5271d15-ccc8-4271-914b-23ed4b6df71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-9.24232031e-01,  7.06010213e-01],\n",
       "         [ 2.92739194e-01, -6.54256192e-01]],\n",
       "\n",
       "        [[-7.42585064e-01,  1.29728310e+00],\n",
       "         [ 2.23668465e-02,  1.51621625e+00]],\n",
       "\n",
       "        [[-1.18307456e-01,  2.66498380e-01],\n",
       "         [ 7.85470442e-01,  1.62879470e+00]]],\n",
       "\n",
       "\n",
       "       [[[-7.30941873e-01, -1.05208280e+00],\n",
       "         [ 6.48386943e-02, -6.13370427e-04]],\n",
       "\n",
       "        [[ 1.11424546e+00,  9.30095427e-01],\n",
       "         [-9.83481872e-02, -2.60299815e-01]],\n",
       "\n",
       "        [[ 4.74490066e-01,  6.20898736e-01],\n",
       "         [ 1.11917893e-02,  8.20782191e-02]]],\n",
       "\n",
       "\n",
       "       [[[-5.41277064e-02,  1.87810951e+00],\n",
       "         [-1.68868570e+00, -4.50950731e-01]],\n",
       "\n",
       "        [[ 8.26093906e-01, -5.85645135e-01],\n",
       "         [-6.27042756e-01,  5.32229719e-02]],\n",
       "\n",
       "        [[-1.27135944e+00,  1.12147565e+00],\n",
       "         [ 1.51815733e-01, -3.94286686e-01]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe49827-1a73-4427-9c2c-5a9211000ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-9.24232031e-01,  2.92739194e-01],\n",
       "         [ 7.06010213e-01, -6.54256192e-01]],\n",
       "\n",
       "        [[-7.42585064e-01,  2.23668465e-02],\n",
       "         [ 1.29728310e+00,  1.51621625e+00]],\n",
       "\n",
       "        [[-1.18307456e-01,  7.85470442e-01],\n",
       "         [ 2.66498380e-01,  1.62879470e+00]]],\n",
       "\n",
       "\n",
       "       [[[-7.30941873e-01,  6.48386943e-02],\n",
       "         [-1.05208280e+00, -6.13370427e-04]],\n",
       "\n",
       "        [[ 1.11424546e+00, -9.83481872e-02],\n",
       "         [ 9.30095427e-01, -2.60299815e-01]],\n",
       "\n",
       "        [[ 4.74490066e-01,  1.11917893e-02],\n",
       "         [ 6.20898736e-01,  8.20782191e-02]]],\n",
       "\n",
       "\n",
       "       [[[-5.41277064e-02, -1.68868570e+00],\n",
       "         [ 1.87810951e+00, -4.50950731e-01]],\n",
       "\n",
       "        [[ 8.26093906e-01, -6.27042756e-01],\n",
       "         [-5.85645135e-01,  5.32229719e-02]],\n",
       "\n",
       "        [[-1.27135944e+00,  1.51815733e-01],\n",
       "         [ 1.12147565e+00, -3.94286686e-01]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1=np.transpose(k,(0,1,3,2))\n",
    "k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d715e6-950b-4c73-8c9d-f812e5233254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
